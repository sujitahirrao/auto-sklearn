{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Test and Train data with Pandas\n\n*auto-sklearn* can automatically encode categorical columns using a label/ordinal encoder.\nThis example highlights how to properly set the dtype in a DataFrame for this to happen,\nand showcase how to input also testing data to autosklearn.\nThe X_train/y_train arguments to the fit function will be used to fit the scikit-learn model,\nwhereas the X_test/y_test will be used to evaluate how good this scikit-learn model generalizes\nto unseen data (i.e. data not in X_train/y_train). Using test data is a good mechanism to measure\nif the trained model suffers from overfit, and more details can be found on `evaluating estimator\nperformance <https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation>`_.\nThis example further highlights through a plot, the best individual models found by *auto-sklearn*\nthrough time (under single_best_optimization_score/single_best_test_score's legend).\nIt also shows the training and test performance of the ensemble build using the best\nperforming models (under ensemble_optimization_score and ensemble_test_score respectively).\n\nThere is also support to manually indicate the feature types (whether a column is categorical\nor numerical) via the argument feat_types from fit(). This is important when working with\nlist or numpy arrays as there is no per-column dtype (further details in the example\n`Continuous and categorical data <example_feature_types.html>`_).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import time\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\n\nfrom smac.tae import StatusType\n\nimport autosklearn.classification\n\n\ndef get_runhistory_models_performance(automl):\n    metric = cls.automl_._metric\n    data = automl.automl_.runhistory_.data\n    performance_list = []\n    for run_key, run_value in data.items():\n        if run_value.status != StatusType.SUCCESS:\n            # Ignore crashed runs\n            continue\n        # Alternatively, it is possible to also obtain the start time with ``run_value.starttime``\n        endtime = pd.Timestamp(time.strftime('%Y-%m-%d %H:%M:%S',\n                                             time.localtime(run_value.endtime)))\n        val_score = metric._optimum - (metric._sign * run_value.cost)\n        test_score = metric._optimum - (metric._sign * run_value.additional_info['test_loss'])\n        train_score = metric._optimum - (metric._sign * run_value.additional_info['train_loss'])\n        performance_list.append({\n            'Timestamp': endtime,\n            'single_best_optimization_score': val_score,\n            'single_best_test_score': test_score,\n            'single_best_train_score': train_score,\n        })\n    return pd.DataFrame(performance_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Using Australian dataset https://www.openml.org/d/40981.\n# This example will use the command fetch_openml, which will\n# download a properly formatted dataframe if you use as_frame=True.\n# For demonstration purposes, we will download a numpy array using\n# as_frame=False, and manually creating the pandas DataFrame\nX, y = sklearn.datasets.fetch_openml(data_id=40981, return_X_y=True, as_frame=False)\n\n# bool and category will be automatically encoded.\n# Targets for classification are also automatically encoded\n# If using fetch_openml, data is already properly encoded, below\n# is an example for user reference\nX = pd.DataFrame(\n    data=X,\n    columns=['A' + str(i) for i in range(1, 15)]\n)\ndesired_boolean_columns = ['A1']\ndesired_categorical_columns = ['A4', 'A5', 'A6', 'A8', 'A9', 'A11', 'A12']\ndesired_numerical_columns = ['A2', 'A3', 'A7', 'A10', 'A13', 'A14']\nfor column in X.columns:\n    if column in desired_boolean_columns:\n        X[column] = X[column].astype('bool')\n    elif column in desired_categorical_columns:\n        X[column] = X[column].astype('category')\n    else:\n        X[column] = pd.to_numeric(X[column])\n\ny = pd.DataFrame(y, dtype='category')\n\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X, y, test_size=0.5, random_state=3\n)\nprint(X.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build and fit a classifier\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cls = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=120,\n    per_run_time_limit=30,\n)\ncls.fit(X_train, y_train, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the Score of the final ensemble\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predictions = cls.predict(X_test)\nprint(\"Accuracy score\", sklearn.metrics.accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the ensemble performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ensemble_performance_frame = pd.DataFrame(cls.automl_.ensemble_performance_history)\nbest_values = pd.Series({'ensemble_optimization_score': -np.inf,\n                         'ensemble_test_score': -np.inf})\nfor idx in ensemble_performance_frame.index:\n    if (\n        ensemble_performance_frame.loc[idx, 'ensemble_optimization_score']\n        > best_values['ensemble_optimization_score']\n    ):\n        best_values = ensemble_performance_frame.loc[idx]\n    ensemble_performance_frame.loc[idx] = best_values\n\nindividual_performance_frame = get_runhistory_models_performance(cls)\nbest_values = pd.Series({'single_best_optimization_score': -np.inf,\n                         'single_best_test_score': -np.inf,\n                         'single_best_train_score': -np.inf})\nfor idx in individual_performance_frame.index:\n    if (\n        individual_performance_frame.loc[idx, 'single_best_optimization_score']\n        > best_values['single_best_optimization_score']\n    ):\n        best_values = individual_performance_frame.loc[idx]\n    individual_performance_frame.loc[idx] = best_values\n\npd.merge(\n    ensemble_performance_frame,\n    individual_performance_frame,\n    on=\"Timestamp\", how='outer'\n).sort_values('Timestamp').fillna(method='ffill').plot(\n    x='Timestamp',\n    kind='line',\n    legend=True,\n    title='Auto-sklearn accuracy over time',\n    grid=True,\n)\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}