
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/80_extending/example_extending_regression.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_80_extending_example_extending_regression.py>`
        to download the full example code or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_80_extending_example_extending_regression.py:


================================================
Extending Auto-Sklearn with Regression Component
================================================

The following example demonstrates how to create a new regression
component for using in auto-sklearn.

.. GENERATED FROM PYTHON SOURCE LINES 9-26

.. code-block:: default


    from ConfigSpace.configuration_space import ConfigurationSpace
    from ConfigSpace.hyperparameters import UniformFloatHyperparameter, \
        UniformIntegerHyperparameter, CategoricalHyperparameter
    from ConfigSpace.conditions import EqualsCondition

    import sklearn.metrics
    import autosklearn.regression
    import autosklearn.pipeline.components.regression
    from autosklearn.pipeline.components.base import AutoSklearnRegressionAlgorithm
    from autosklearn.pipeline.constants import SPARSE, DENSE, \
        SIGNED_DATA, UNSIGNED_DATA, PREDICTIONS

    from sklearn.datasets import load_diabetes
    from sklearn.model_selection import train_test_split









.. GENERATED FROM PYTHON SOURCE LINES 27-29

Implement kernel ridge regression component for auto-sklearn
============================================================

.. GENERATED FROM PYTHON SOURCE LINES 29-106

.. code-block:: default


    class KernelRidgeRegression(AutoSklearnRegressionAlgorithm):
        def __init__(self, alpha, kernel, gamma, degree, coef0, random_state=None):
            self.alpha = alpha
            self.kernel = kernel
            self.gamma = gamma
            self.degree = degree
            self.coef0 = coef0
            self.random_state = random_state
            self.estimator = None

        def fit(self, X, y):
            self.alpha = float(self.alpha)
            self.gamma = float(self.gamma)
            self.degree = int(self.degree)
            self.coef0 = float(self.coef0)

            import sklearn.kernel_ridge
            self.estimator = sklearn.kernel_ridge.KernelRidge(alpha=self.alpha,
                                                              kernel=self.kernel,
                                                              gamma=self.gamma,
                                                              degree=self.degree,
                                                              coef0=self.coef0,
                                                              )
            self.estimator.fit(X, y)
            return self

        def predict(self, X):
            if self.estimator is None:
                raise NotImplementedError
            return self.estimator.predict(X)

        @staticmethod
        def get_properties(dataset_properties=None):
            return {'shortname': 'KRR',
                    'name': 'Kernel Ridge Regression',
                    'handles_regression': True,
                    'handles_classification': False,
                    'handles_multiclass': False,
                    'handles_multilabel': False,
                    'handles_multioutput': True,
                    'is_deterministic': True,
                    'input': (SPARSE, DENSE, UNSIGNED_DATA, SIGNED_DATA),
                    'output': (PREDICTIONS,)}

        @staticmethod
        def get_hyperparameter_search_space(dataset_properties=None):
            cs = ConfigurationSpace()
            alpha = UniformFloatHyperparameter(
                name='alpha', lower=10 ** -5, upper=1, log=True, default_value=1.0)
            kernel = CategoricalHyperparameter(
                name='kernel',
                # We restrict ourselves to two possible kernels for this example
                choices=['polynomial', 'rbf'],
                default_value='polynomial'
            )
            gamma = UniformFloatHyperparameter(
                name='gamma', lower=0.00001, upper=1, default_value=0.1, log=True
            )
            degree = UniformIntegerHyperparameter(
                name='degree', lower=2, upper=5, default_value=3
            )
            coef0 = UniformFloatHyperparameter(
                name='coef0', lower=1e-2, upper=1e2, log=True, default_value=1,
            )
            cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])
            degree_condition = EqualsCondition(degree, kernel, 'polynomial')
            coef0_condition = EqualsCondition(coef0, kernel, 'polynomial')
            cs.add_conditions([degree_condition, coef0_condition])
            return cs


    # Add KRR component to auto-sklearn.
    autosklearn.pipeline.components.regression.add_regressor(KernelRidgeRegression)
    cs = KernelRidgeRegression.get_hyperparameter_search_space()
    print(cs)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:88: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      degree = UniformIntegerHyperparameter(
    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:94: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])
    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:94: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])
    Configuration space object:
      Hyperparameters:
        alpha, Type: UniformFloat, Range: [1e-05, 1.0], Default: 1.0, on log-scale
        coef0, Type: UniformFloat, Range: [0.01, 100.0], Default: 1.0, on log-scale
        degree, Type: UniformInteger, Range: [2, 5], Default: 3
        gamma, Type: UniformFloat, Range: [1e-05, 1.0], Default: 0.1, on log-scale
        kernel, Type: Categorical, Choices: {polynomial, rbf}, Default: polynomial
      Conditions:
        coef0 | kernel == 'polynomial'
        degree | kernel == 'polynomial'





.. GENERATED FROM PYTHON SOURCE LINES 107-109

Generate data
=============

.. GENERATED FROM PYTHON SOURCE LINES 109-113

.. code-block:: default


    X, y = load_diabetes(return_X_y=True)
    X_train, X_test, y_train, y_test = train_test_split(X, y)








.. GENERATED FROM PYTHON SOURCE LINES 114-116

Fit the model using KRR
=======================

.. GENERATED FROM PYTHON SOURCE LINES 116-128

.. code-block:: default


    reg = autosklearn.regression.AutoSklearnRegressor(
        time_left_for_this_task=30,
        per_run_time_limit=10,
        include_estimators=['KernelRidgeRegression'],
        # Bellow two flags are provided to speed up calculations
        # Not recommended for a real implementation
        initial_configurations_via_metalearning=0,
        smac_scenario_args={'runcount_limit': 5},
    )
    reg.fit(X_train, y_train)





.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:88: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      degree = UniformIntegerHyperparameter(
    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:94: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])
    /home/runner/work/auto-sklearn/auto-sklearn/examples/80_extending/example_extending_regression.py:94: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
    Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
      cs.add_hyperparameters([alpha, kernel, gamma, degree, coef0])

    AutoSklearnRegressor(include_estimators=['KernelRidgeRegression'],
                         initial_configurations_via_metalearning=0,
                         per_run_time_limit=10,
                         smac_scenario_args={'runcount_limit': 5},
                         time_left_for_this_task=30)



.. GENERATED FROM PYTHON SOURCE LINES 129-131

Print prediction score and statistics
=====================================

.. GENERATED FROM PYTHON SOURCE LINES 131-134

.. code-block:: default

    y_pred = reg.predict(X_test)
    print("r2 score: ", sklearn.metrics.r2_score(y_pred, y_test))
    print(reg.show_models())




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    r2 score:  -0.32646104686397215
    [(1.000000, SimpleRegressionPipeline({'data_preprocessing:categorical_transformer:categorical_encoding:__choice__': 'one_hot_encoding', 'data_preprocessing:categorical_transformer:category_coalescence:__choice__': 'minority_coalescer', 'data_preprocessing:numerical_transformer:imputation:strategy': 'mean', 'data_preprocessing:numerical_transformer:rescaling:__choice__': 'standardize', 'feature_preprocessor:__choice__': 'no_preprocessing', 'regressor:__choice__': 'KernelRidgeRegression', 'data_preprocessing:categorical_transformer:category_coalescence:minority_coalescer:minimum_fraction': 0.01, 'regressor:KernelRidgeRegression:alpha': 1.0, 'regressor:KernelRidgeRegression:gamma': 0.1, 'regressor:KernelRidgeRegression:kernel': 'polynomial', 'regressor:KernelRidgeRegression:coef0': 1.0, 'regressor:KernelRidgeRegression:degree': 3},
    dataset_properties={
      'task': 4,
      'sparse': False,
      'multioutput': False,
      'target_type': 'regression',
      'signed': False})),
    ]





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  13.495 seconds)


.. _sphx_glr_download_examples_80_extending_example_extending_regression.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example


  .. container:: binder-badge

    .. image:: images/binder_badge_logo.svg
      :target: https://mybinder.org/v2/gh/automl/auto-sklearn/master?urlpath=lab/tree/notebooks/examples/80_extending/example_extending_regression.ipynb
      :alt: Launch binder
      :width: 150 px


  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_extending_regression.py <example_extending_regression.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_extending_regression.ipynb <example_extending_regression.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
